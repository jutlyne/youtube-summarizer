import 'dotenv/config'
import https from 'https';
import yt from '@vreden/youtube_scraper';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';
import { GoogleGenAI } from '@google/genai';
import { SpeechClient } from '@google-cloud/speech';
import { TextToSpeechClient } from '@google-cloud/text-to-speech';
import { Storage } from '@google-cloud/storage';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const KEY_FILE_PATH = join(__dirname, 'key.json');

export const GCS_BUCKET_NAME = 'youtube-audio-bucket-kyvc';

const speechClient = new SpeechClient({
  keyFile: KEY_FILE_PATH,
});
const ttsClient = new TextToSpeechClient({
  keyFilename: KEY_FILE_PATH,
});
const storageClient = new Storage({
  keyFilename: KEY_FILE_PATH,
});
const ai = new GoogleGenAI({
  apiKey: process.env.GOOGLE_GEN_AI_API_KEY,
});

/**
 * L·∫•y URL audio t·ª´ YouTube v√† truy·ªÅn t·∫£i tr·ª±c ti·∫øp l√™n GCS.
 * KH√îNG L∆ØU FILE C·ª§C B·ªò.
 * @param {string} youtubeUrl URL c·ªßa video YouTube.
 * @param {string} gcsFileName T√™n file s·∫Ω ƒë∆∞·ª£c l∆∞u tr√™n GCS.
 * @returns {Promise<string>} Promise resolve v·ªõi URI GCS (vd: 'gs://bucket-name/file-name').
 */
export async function streamAudioToGCS(youtubeUrl, gcsFileName) {
  console.log(
    '-> üéµ ƒêang t√¨m ki·∫øm link audio v√† truy·ªÅn t·∫£i tr·ª±c ti·∫øp l√™n GCS...'
  );

  const ytmp3Result = await yt.ytmp3(youtubeUrl, 128);
  if (
    !ytmp3Result.status ||
    typeof ytmp3Result.download !== 'object' ||
    typeof ytmp3Result.download.url !== 'string' ||
    ytmp3Result.download.url.length === 0
  ) {
    throw new Error('Kh√¥ng th·ªÉ t√¨m th·∫•y link t·∫£i audio h·ª£p l·ªá.');
  }

  const downloadUrl = ytmp3Result.download.url;
  console.log(
    `-> üîó ƒê√£ t√¨m th·∫•y URL t·∫£i xu·ªëng: ${downloadUrl.substring(0, 50)}...`
  );

  return new Promise((resolve, reject) => {
    const bucket = storageClient.bucket(GCS_BUCKET_NAME);
    const file = bucket.file(gcsFileName);

    const gcsWriteStream = file.createWriteStream({
      metadata: {
        contentType: 'audio/mp3',
      },
    });

    gcsWriteStream.on('error', (err) => {
      console.error('L·ªói GCS Write Stream:', err.message);
      reject(
        new Error('L·ªói khi ghi v√†o Google Cloud Storage. Ki·ªÉm tra quy·ªÅn GCS.')
      );
    });

    gcsWriteStream.on('finish', () => {
      const gcsUri = `gs://${GCS_BUCKET_NAME}/${gcsFileName}`;
      console.log(`-> ‚úÖ Truy·ªÅn t·∫£i v√† ghi v√†o GCS th√†nh c√¥ng: ${gcsUri}`);
      resolve(gcsUri);
    });

    const request = https.get(downloadUrl, (response) => {
      if (response.statusCode < 200 || response.statusCode >= 300) {
        request.destroy();
        return reject(
          new Error(
            `L·ªói HTTP khi t·∫£i audio (${response.statusCode}): ${response.statusMessage}`
          )
        );
      }

      response.pipe(gcsWriteStream);
    });

    request.on('error', (err) => {
      gcsWriteStream.end();
      reject(err);
    });
  });
}

/**
 * Chuy·ªÉn ƒë·ªïi file audio GCS th√†nh vƒÉn b·∫£n ti·∫øng Vi·ªát s·ª≠ d·ª•ng Long Running Recognition,
 * tr√≠ch xu·∫•t c·∫£ d·∫•u th·ªùi gian.
 * @param {string} gcsUri URI GCS c·ªßa file audio.
 * @returns {Promise<string>} Promise resolve v·ªõi b·∫£n ch√©p l·ªùi k√®m d·∫•u th·ªùi gian.
 */
export async function transcribeAudio(gcsUri) {
  console.log(
    '-> üó£Ô∏è ƒêang g·ª≠i y√™u c·∫ßu nh·∫≠n d·∫°ng d√†i h·∫°n (Long Running Recognition) t·ªõi Speech-to-Text API, ƒê√É K√çCH HO·∫†T D·∫§U TH·ªúI GIAN...'
  );

  const audio = {
    uri: gcsUri,
  };

  const config = {
    encoding: 'MP3',
    languageCode: 'vi-VN',
    enableAutomaticPunctuation: true,
    enableSpeakerDiarization: true,
    sampleRateHertz: 44100,
    enableWordTimeOffsets: true,
  };

  const request = {
    audio: audio,
    config: config,
  };

  try {
    const [operation] = await speechClient.longRunningRecognize(request);

    console.log(
      '-> ‚è≥ ƒêang ch·ªù k·∫øt qu·∫£ nh·∫≠n d·∫°ng t·ª´ API (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)...'
    );

    const [response] = await operation.promise();

    let detailedTranscription = '';

    response.results.forEach((result) => {
      if (result.alternatives[0].words) {
        result.alternatives[0].words.forEach((word) => {
          const totalSeconds = parseInt(word.startTime.seconds);
          const minutes = Math.floor(totalSeconds / 60);
          const seconds = totalSeconds % 60;
          const formattedTime = `[${minutes
            .toString()
            .padStart(2, '0')}:${seconds.toString().padStart(2, '0')}]`;

          detailedTranscription += `${formattedTime} ${word.word} `;
        });
        detailedTranscription += '\n';
      } else {
        detailedTranscription += result.alternatives[0].transcript + '\n';
      }
    });

    console.log('-> ‚úÖ Chuy·ªÉn text ho√†n t·∫•t.');
    return detailedTranscription.trim();
  } catch (error) {
    console.error(
      'L·ªói khi chuy·ªÉn text b·∫±ng Long Running Recognize:',
      error.message
    );
    throw new Error(
      'L·ªói Speech-to-Text. Ki·ªÉm tra c·∫•u h√¨nh GCS, quy·ªÅn truy c·∫≠p v√† ƒë·ªãnh d·∫°ng audio.'
    );
  }
}

/**
 * G·ª≠i b·∫£n ch√©p l·ªùi cho Gemini ƒë·ªÉ t√≥m t·∫Øt n·ªôi dung ch√≠nh.
 * @param {string} text VƒÉn b·∫£n c·∫ßn t√≥m t·∫Øt.
 * @returns {Promise<string>} Promise resolve v·ªõi b·∫£n t√≥m t·∫Øt.
 */
export async function summarizeTextWithGemini(text) {
  console.log('-> üß† ƒêang g·ª≠i text cho Gemini ƒë·ªÉ t√≥m t·∫Øt...');

  const prompt = `
    B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt n·ªôi dung video chuy√™n nghi·ªáp.
    H√£y t√≥m t·∫Øt vƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c ch√©p l·ªùi sau ƒë√¢y. B·∫£n t√≥m t·∫Øt c·ªßa b·∫°n ph·∫£i:
    1. S·ª≠ d·ª•ng ti·∫øng Vi·ªát.
    2. C·ª±c k·ª≥ chi ti·∫øt, r√µ r√†ng v√† c√¥ ƒë·ªçng, t·∫≠p trung v√†o c√°c s·ª± ki·ªán, quan s√°t v√† ƒëi·ªÉm nh·∫•n ch√≠nh.
    3. B·∫Øt bu·ªôc ph·∫£i **ph√¢n ƒëo·∫°n n·ªôi dung** th√†nh c√°c m·ª•c l·ªõn v√† m·ª•c nh·ªè, d·ª±a tr√™n ch·ªß ƒë·ªÅ (v√≠ d·ª•: Gi·ªõi Thi·ªáu, Quan S√°t, Tr·∫£i Nghi·ªám, Ti·∫øt L·ªô Gi√° C·∫£, K·∫øt Lu·∫≠n...).
    4. **B·∫ÆT BU·ªòC** tr√≠ch d·∫´n d·∫•u th·ªùi gian ([ph√∫t:gi√¢y] ho·∫∑c [ph√∫t:gi√¢y]‚Äì[ph√∫t:gi√¢y]) ngay sau m·ªói √Ω ch√≠nh ho·∫∑c nh√≥m √Ω ch√≠nh.

    C·∫•u tr√∫c T√≥m t·∫Øt ƒë·ªÅ xu·∫•t:
    - T√™n T√≥m T·∫Øt (v√≠ d·ª•: T√≥m T·∫Øt N·ªôi Dung Video)
    - M·ª•c 1: Gi·ªõi Thi·ªáu/B·ªëi C·∫£nh (k√®m timestamp)
    - M·ª•c 2: Quan S√°t Tr√™n ƒê∆∞·ªùng Ph·ªë (k√®m timestamp)
    - M·ª•c 3: Tr·∫£i Nghi·ªám C·ª• Th·ªÉ (v√≠ d·ª•: Qu√°n Bar, t∆∞∆°ng t√°c) (k√®m timestamp)
    - M·ª•c 4: Ti·∫øt L·ªô Gi√° C·∫£ v√† Quan ƒêi·ªÉm C√° Nh√¢n (k√®m timestamp)
    - M·ª•c 5: K·∫øt Th√∫c/Quan S√°t Cu·ªëi C√πng (k√®m timestamp)

    D∆∞·ªõi ƒë√¢y l√† vƒÉn b·∫£n ƒë√£ ch√©p l·ªùi t·ª´ video:

    ---
    ${text}
    ---
    `;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: prompt,
    });

    console.log('-> ‚úÖ T√≥m t·∫Øt ho√†n t·∫•t b·∫±ng Gemini.');
    return response.text;
  } catch (error) {
    console.error('L·ªói khi t√≥m t·∫Øt b·∫±ng Gemini:', error.message);
    throw error;
  }
}

/**
 * X√≥a file tr√™n GCS sau khi x·ª≠ l√Ω xong.
 * @param {string} gcsFileName T√™n file tr√™n GCS.
 */
export async function deleteGCSFile(gcsFileName) {
  if (!gcsFileName) return;
  try {
    await storageClient.bucket(GCS_BUCKET_NAME).file(gcsFileName).delete();
    console.log(`-> ƒê√£ x√≥a file t·∫°m th·ªùi tr√™n GCS: ${gcsFileName}`);
  } catch (e) {
    console.warn(
      `C·∫£nh b√°o: Kh√¥ng th·ªÉ x√≥a file GCS ${gcsFileName}. Vui l√≤ng ki·ªÉm tra quy·ªÅn Storage Object Deleter.`
    );
  }
}

/**
 * S·ª≠ d·ª•ng Google Cloud Text-to-Speech ƒë·ªÉ chuy·ªÉn vƒÉn b·∫£n th√†nh audio buffer.
 * @param {string} text VƒÉn b·∫£n c·∫ßn chuy·ªÉn th√†nh gi·ªçng n√≥i.
 * @returns {Promise<Buffer>} Buffer ch·ª©a d·ªØ li·ªáu audio MP3.
 */
export async function generateSpeechAudio(text) {
  console.log('-> üé§ ƒêang g·ª≠i text cho Google Cloud Text-to-Speech...');

  const request = {
    input: { text: text },
    voice: { languageCode: 'vi-VN', name: 'vi-VN-Neural2-A' },
    audioConfig: { audioEncoding: 'MP3', speakingRate: 1.25 },
  };

  try {
    const [response] = await ttsClient.synthesizeSpeech(request);
    console.log('-> ‚úÖ Text-to-Speech ho√†n t·∫•t, tr·∫£ v·ªÅ audio buffer.');
    return response.audioContent;
  } catch (error) {
    console.error('L·ªói khi g·ªçi Google Cloud Text-to-Speech:', error.message);
    throw new Error('Kh√¥ng th·ªÉ t·∫°o gi·ªçng n√≥i t·ª´ vƒÉn b·∫£n.');
  }
}
